{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef876b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "# import arabicstopwords.arabicstopwords as stp\n",
    "from __future__ import unicode_literals\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e09938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df=pd.read_csv(\"final_dialect_dataset_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1741b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IQ', 'LY', 'QA', 'PL', 'SY', 'TN', 'JO', 'MA', 'SA', 'YE', 'DZ',\n",
       "       'EG', 'LB', 'KW', 'OM', 'SD', 'AE', 'BH'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_df['dialect'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c605ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df=dialect_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6ad2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialect</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema مبين من كلامه خليجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@HAIDER76128900 يسلملي مرورك وروحك الحلوه💐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@hmo2406 وين هل الغيبه  اخ محمد 🌸🌺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>BH</td>\n",
       "      <td>@Al_mhbaa_7 مبسوطين منك اللي باسطانا😅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>BH</td>\n",
       "      <td>@Zzainabali @P_ameerah والله ماينده ابش يختي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>BH</td>\n",
       "      <td>@Al_mhbaa_7 شو عملنا لك حنا تهربي مننا احنا مس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>BH</td>\n",
       "      <td>@haneenalmwla الله يبارك فيها وبالعافيه 😋😋😋</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>BH</td>\n",
       "      <td>@jolnar121 السحله ضيفي ي بتطلع لك سحليه😅😅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dialect                                            content\n",
       "0           IQ   @Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .\n",
       "1           IQ  @7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...\n",
       "2           IQ                    @KanaanRema مبين من كلامه خليجي\n",
       "3           IQ         @HAIDER76128900 يسلملي مرورك وروحك الحلوه💐\n",
       "4           IQ                 @hmo2406 وين هل الغيبه  اخ محمد 🌸🌺\n",
       "...        ...                                                ...\n",
       "458192      BH              @Al_mhbaa_7 مبسوطين منك اللي باسطانا😅\n",
       "458193      BH       @Zzainabali @P_ameerah والله ماينده ابش يختي\n",
       "458194      BH  @Al_mhbaa_7 شو عملنا لك حنا تهربي مننا احنا مس...\n",
       "458195      BH        @haneenalmwla الله يبارك فيها وبالعافيه 😋😋😋\n",
       "458196      BH          @jolnar121 السحله ضيفي ي بتطلع لك سحليه😅😅\n",
       "\n",
       "[458197 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b78846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      @Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .\n",
       "1     @7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. ح...\n",
       "2                       @KanaanRema مبين من كلامه خليجي\n",
       "3            @HAIDER76128900 يسلملي مرورك وروحك الحلوه💐\n",
       "4                    @hmo2406 وين هل الغيبه  اخ محمد 🌸🌺\n",
       "                            ...                        \n",
       "95    @Rahhafjaseeeeem @AliAljarah16 حلوه بالعراق ان...\n",
       "96    @AmeenPress سنة يسولف برفع الصبات واللي اعتبره...\n",
       "97    @OmarAlmansuri هذا كله  حتى يبقى اقتصاد ايران ...\n",
       "98                    @OmarAlmansuri كبسولة كل ست ساعات\n",
       "99             @LaylaKilani صدقتي عزيزتي .. يسعد مساك 🌸\n",
       "Name: content, Length: 100, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_df['content'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58d5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ar(text):\n",
    "    return re.sub('([@A-Za-z0-9_]+)|[^\\w\\s]|#|http\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d815b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df['content']=dialect_df['content'].apply(remove_non_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52e7181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =['من',\n",
    " 'في',\n",
    " 'على',\n",
    " 'و',\n",
    " 'فى',\n",
    " 'يا',\n",
    " 'عن',\n",
    " 'مع',\n",
    " 'ان',\n",
    " 'هو',\n",
    " 'علي',\n",
    " 'ما',\n",
    " 'اللي',\n",
    " 'كل',\n",
    " 'بعد',\n",
    " 'ده',\n",
    " 'اليوم',\n",
    " 'أن',\n",
    " 'يوم',\n",
    " 'انا',\n",
    " 'إلى',\n",
    " 'كان',\n",
    " 'ايه',\n",
    " 'اللى',\n",
    " 'الى',\n",
    " 'دي',\n",
    " 'بين',\n",
    " 'انت',\n",
    " 'أنا',\n",
    " 'حتى',\n",
    " 'لما',\n",
    " 'فيه',\n",
    " 'هذا',\n",
    " 'واحد',\n",
    " 'احنا',\n",
    " 'اي',\n",
    " 'كده',\n",
    " 'إن',\n",
    " 'او',\n",
    " 'أو',\n",
    " 'عليه',\n",
    " 'ف',\n",
    " 'دى',\n",
    " 'مين',\n",
    " 'الي',\n",
    " 'كانت',\n",
    " 'أمام',\n",
    " 'زي',\n",
    " 'يكون',\n",
    " 'خلال',\n",
    " 'ع',\n",
    " 'كنت',\n",
    " 'هي',\n",
    " 'فيها',\n",
    " 'عند',\n",
    " 'التي',\n",
    " 'الذي',\n",
    " 'قال',\n",
    " 'هذه',\n",
    " 'قد',\n",
    " 'انه',\n",
    " 'ريتويت',\n",
    " 'بعض',\n",
    " 'أول',\n",
    " 'ايه',\n",
    " 'الان',\n",
    " 'أي',\n",
    " 'منذ',\n",
    " 'عليها',\n",
    " 'له',\n",
    " 'ال',\n",
    " 'تم',\n",
    " 'ب',\n",
    " 'دة',\n",
    " 'عليك',\n",
    " 'اى',\n",
    " 'كلها',\n",
    " 'اللتى',\n",
    " 'هى',\n",
    " 'دا',\n",
    " 'انك',\n",
    " 'وهو',\n",
    " 'ومن',\n",
    " 'منك',\n",
    " 'نحن',\n",
    " 'زى',\n",
    " 'أنت',\n",
    " 'انهم',\n",
    " 'معانا',\n",
    " 'حتي',\n",
    " 'وانا',\n",
    " 'عنه',\n",
    " 'إلي',\n",
    " 'ونحن',\n",
    " 'وانت',\n",
    " 'منكم',\n",
    " 'وان',\n",
    " 'معاهم',\n",
    " 'معايا',\n",
    " 'وأنا',\n",
    " 'عنها',\n",
    " 'إنه',\n",
    " 'اني',\n",
    " 'معك',\n",
    " 'اننا',\n",
    " 'فيهم',\n",
    " 'د',\n",
    " 'انتا',\n",
    " 'عنك',\n",
    " 'وهى',\n",
    " 'معا',\n",
    " 'آن',\n",
    " 'انتي',\n",
    " 'وأنت',\n",
    " 'وإن',\n",
    " 'ومع',\n",
    " 'وعن',\n",
    " 'معاكم',\n",
    " 'معاكو',\n",
    " 'معاها',\n",
    " 'وعليه',\n",
    " 'وانتم',\n",
    " 'وانتي',\n",
    " '¿',\n",
    " '|']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec1ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_ar_stopwords(text):\n",
    "    \"\"\"\n",
    "        Here we remove all Arabic stop words\n",
    "        \n",
    "    \"\"\"\n",
    "      # if read it from file\n",
    "#     ar_stopwords_list = open(\"arabic_stopwords.txt\", \"r\") \n",
    "#     stop_words = ar_stopwords_list.read().split(\"\\n\")\n",
    "#     stop_words = []\n",
    "    original_words = []\n",
    "    words = word_tokenize(text) # it works on one hadith not list\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            original_words.append(word)\n",
    "    filtered_sentence = \" \".join(original_words)\n",
    "    return filtered_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c019fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df['content']=dialect_df['content'].apply(removing_ar_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "189ea908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_letters(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4200d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df['content']=dialect_df['content'].apply(remove_duplicate_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e273ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_df.to_csv('final_data_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
