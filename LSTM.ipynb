{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7113803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-14 20:17:22--  https://archive.org/download/full_grams_cbow_300_twitter/full_grams_cbow_300_twitter.zip\n",
      "Resolving archive.org (archive.org)... 207.241.224.2\n",
      "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ia802803.us.archive.org/15/items/full_grams_cbow_300_twitter/full_grams_cbow_300_twitter.zip [following]\n",
      "--2022-03-14 20:17:23--  https://ia802803.us.archive.org/15/items/full_grams_cbow_300_twitter/full_grams_cbow_300_twitter.zip\n",
      "Resolving ia802803.us.archive.org (ia802803.us.archive.org)... 207.241.232.113\n",
      "Connecting to ia802803.us.archive.org (ia802803.us.archive.org)|207.241.232.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3325529808 (3.1G) [application/zip]\n",
      "Saving to: ‘full_grams_cbow_300_twitter.zip’\n",
      "\n",
      "                 fu  20%[===>                ] 648.38M   595KB/s    eta 78m 27s"
     ]
    }
   ],
   "source": [
    "!wget https://archive.org/download/full_grams_cbow_300_twitter/full_grams_cbow_300_twitter.zip\n",
    "!unzip full_grams_cbow_300_twitter.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdacdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea56d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 20:12:10.774128: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-14 20:12:10.774162: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100000)\n",
    "# import Data_Preprocessing as dp\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "from tensorflow.keras.models import load_model\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8760107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dialect</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>IQ</td>\n",
       "      <td>لكن بالنهاية ينتفض يغير</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يعني محسوب البشر حيونه وحشيه وتطلبون الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IQ</td>\n",
       "      <td>مبين كلامه خليجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>IQ</td>\n",
       "      <td>يسلملي مرورك وروحك الحلوه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>IQ</td>\n",
       "      <td>وين هل الغيبه اخ محمد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458192</th>\n",
       "      <td>458192</td>\n",
       "      <td>BH</td>\n",
       "      <td>مبسوطين باسطانا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458193</th>\n",
       "      <td>458193</td>\n",
       "      <td>BH</td>\n",
       "      <td>واله ماينده ابش يختي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458194</th>\n",
       "      <td>458194</td>\n",
       "      <td>BH</td>\n",
       "      <td>شو عملنا لك حنا تهربي منا مساكين ليش بتعملي هيك فينا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458195</th>\n",
       "      <td>458195</td>\n",
       "      <td>BH</td>\n",
       "      <td>اله يبارك وبالعافيه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458196</th>\n",
       "      <td>458196</td>\n",
       "      <td>BH</td>\n",
       "      <td>السحله ضيفي ي بتطلع لك سحليه</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458197 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 dialect  \\\n",
       "0                0      IQ   \n",
       "1                1      IQ   \n",
       "2                2      IQ   \n",
       "3                3      IQ   \n",
       "4                4      IQ   \n",
       "...            ...     ...   \n",
       "458192      458192      BH   \n",
       "458193      458193      BH   \n",
       "458194      458194      BH   \n",
       "458195      458195      BH   \n",
       "458196      458196      BH   \n",
       "\n",
       "                                                                                   content  \n",
       "0                                                                  لكن بالنهاية ينتفض يغير  \n",
       "1       يعني محسوب البشر حيونه وحشيه وتطلبون الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب  \n",
       "2                                                                         مبين كلامه خليجي  \n",
       "3                                                                يسلملي مرورك وروحك الحلوه  \n",
       "4                                                                    وين هل الغيبه اخ محمد  \n",
       "...                                                                                    ...  \n",
       "458192                                                                     مبسوطين باسطانا  \n",
       "458193                                                                واله ماينده ابش يختي  \n",
       "458194                                شو عملنا لك حنا تهربي منا مساكين ليش بتعملي هيك فينا  \n",
       "458195                                                                 اله يبارك وبالعافيه  \n",
       "458196                                                        السحله ضيفي ي بتطلع لك سحليه  \n",
       "\n",
       "[458197 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('final_data_cleaned.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab1c1b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['dialect'].astype(str)\n",
    "X= df['content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b4fe2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(X , y,test_size=0.2 ,stratify=df['dialect'], random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa042f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d05eb3f",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "476e52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b629590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(t, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a6fb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pickle.load(open('tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8049a189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425968"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8824826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "encoded_X_train = t.texts_to_sequences(X_train)\n",
    "encoded_X_test = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2202295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280\n"
     ]
    }
   ],
   "source": [
    "max_len=0\n",
    "for i in X_train:\n",
    "    max_len=max(len(i),max_len)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d22626fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "padded_X_train = pad_sequences(encoded_X_train, maxlen=max_len, padding='post')\n",
    "padded_X_test = pad_sequences(encoded_X_test, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1875ce22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366557"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ff6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the whole embedding into memory\n",
    "w2v_embeddings_index={}\n",
    "TOTAL_EMBEDDING_DIM=300\n",
    "embeddings_file=\"D:/full_grams_cbow_300_twitter/full_grams_cbow_300_twitter.mdl\"\n",
    "w2v_model =KeyedVectors.load(embeddings_file)\n",
    "for word in w2v_model.wv.vocab:\n",
    "    w2v_embeddings_index[word] = w2v_model[word]\n",
    "print('Loaded %s word vectors.'% len(w2v_embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, TOTAL_EMBEDDING_DIM))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = w2v_embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print('Embedding Matrix shape:', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={'AE': 16,'BH': 17,'DZ': 10,'EG': 11,'IQ': 0,'JO': 6,'KW': 13,'LB': 12,'LY': 1,'MA': 7,'OM': 14,'PL': 3,\n",
    "         'QA': 2,'SA': 8,'SD': 15,'SY': 4,'TN': 5,'YE': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.apply(lambda x: mapping[x])\n",
    "Y_test = Y_test.apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60751fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=tf.keras.utils.to_categorical(Y_train, num_classes = 18)\n",
    "Y_test=tf.keras.utils.to_categorical(Y_test, num_classes = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, TOTAL_EMBEDDING_DIM, weights=[embedding_matrix], input_length=max_len, trainable=False),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(18, activation='softmax'),\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a50c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bilstm.fit(padded_X_train,\n",
    "                     Y_train,\n",
    "                     epochs = 5,\n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f1046",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.evaluate(padded_X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29169d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = load_model('lstm_model.h5')\n",
    "tok = pickle.load(open('tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lstm = tok.texts_to_sequences(X_test)\n",
    "X_test_lstm = pad_sequences(X_test_lstm, maxlen=280, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lstm = lstm_model.predict(X_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f246e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lstm1=[np.argmax(i) for i in Y_pred_lstm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_pred_lstm1)):\n",
    "    for k, v in mapping.items():\n",
    "        if v == Y_pred_lstm1[i]:\n",
    "            Y_pred_lstm1[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lstm = pd.Series(Y_pred_lstm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test , Y_pred_lstm ,target_names=df['dialect'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6def8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
