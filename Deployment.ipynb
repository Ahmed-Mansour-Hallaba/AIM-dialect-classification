{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask,render_template,request\n",
    "import requests\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ar(text):\n",
    "    return re.sub('([@A-Za-z0-9_]+)|[^\\w\\s]|#|http\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =['من',\n",
    " 'في',\n",
    " 'على',\n",
    " 'و',\n",
    " 'فى',\n",
    " 'يا',\n",
    " 'عن',\n",
    " 'مع',\n",
    " 'ان',\n",
    " 'هو',\n",
    " 'علي',\n",
    " 'ما',\n",
    " 'اللي',\n",
    " 'كل',\n",
    " 'بعد',\n",
    " 'ده',\n",
    " 'اليوم',\n",
    " 'أن',\n",
    " 'يوم',\n",
    " 'انا',\n",
    " 'إلى',\n",
    " 'كان',\n",
    " 'ايه',\n",
    " 'اللى',\n",
    " 'الى',\n",
    " 'دي',\n",
    " 'بين',\n",
    " 'انت',\n",
    " 'أنا',\n",
    " 'حتى',\n",
    " 'لما',\n",
    " 'فيه',\n",
    " 'هذا',\n",
    " 'واحد',\n",
    " 'احنا',\n",
    " 'اي',\n",
    " 'كده',\n",
    " 'إن',\n",
    " 'او',\n",
    " 'أو',\n",
    " 'عليه',\n",
    " 'ف',\n",
    " 'دى',\n",
    " 'مين',\n",
    " 'الي',\n",
    " 'كانت',\n",
    " 'أمام',\n",
    " 'زي',\n",
    " 'يكون',\n",
    " 'خلال',\n",
    " 'ع',\n",
    " 'كنت',\n",
    " 'هي',\n",
    " 'فيها',\n",
    " 'عند',\n",
    " 'التي',\n",
    " 'الذي',\n",
    " 'قال',\n",
    " 'هذه',\n",
    " 'قد',\n",
    " 'انه',\n",
    " 'ريتويت',\n",
    " 'بعض',\n",
    " 'أول',\n",
    " 'ايه',\n",
    " 'الان',\n",
    " 'أي',\n",
    " 'منذ',\n",
    " 'عليها',\n",
    " 'له',\n",
    " 'ال',\n",
    " 'تم',\n",
    " 'ب',\n",
    " 'دة',\n",
    " 'عليك',\n",
    " 'اى',\n",
    " 'كلها',\n",
    " 'اللتى',\n",
    " 'هى',\n",
    " 'دا',\n",
    " 'انك',\n",
    " 'وهو',\n",
    " 'ومن',\n",
    " 'منك',\n",
    " 'نحن',\n",
    " 'زى',\n",
    " 'أنت',\n",
    " 'انهم',\n",
    " 'معانا',\n",
    " 'حتي',\n",
    " 'وانا',\n",
    " 'عنه',\n",
    " 'إلي',\n",
    " 'ونحن',\n",
    " 'وانت',\n",
    " 'منكم',\n",
    " 'وان',\n",
    " 'معاهم',\n",
    " 'معايا',\n",
    " 'وأنا',\n",
    " 'عنها',\n",
    " 'إنه',\n",
    " 'اني',\n",
    " 'معك',\n",
    " 'اننا',\n",
    " 'فيهم',\n",
    " 'د',\n",
    " 'انتا',\n",
    " 'عنك',\n",
    " 'وهى',\n",
    " 'معا',\n",
    " 'آن',\n",
    " 'انتي',\n",
    " 'وأنت',\n",
    " 'وإن',\n",
    " 'ومع',\n",
    " 'وعن',\n",
    " 'معاكم',\n",
    " 'معاكو',\n",
    " 'معاها',\n",
    " 'وعليه',\n",
    " 'وانتم',\n",
    " 'وانتي',\n",
    " '¿',\n",
    " '|']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec1ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_ar_stopwords(text):\n",
    "    \"\"\"\n",
    "        Here we remove all Arabic stop words\n",
    "        \n",
    "    \"\"\"\n",
    "      # if read it from file\n",
    "#     ar_stopwords_list = open(\"arabic_stopwords.txt\", \"r\") \n",
    "#     stop_words = ar_stopwords_list.read().split(\"\\n\")\n",
    "#     stop_words = []\n",
    "    original_words = []\n",
    "    words = word_tokenize(text) # it works on one hadith not list\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            original_words.append(word)\n",
    "    filtered_sentence = \" \".join(original_words)\n",
    "    return filtered_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ea908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_letters(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eeca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesss(text):\n",
    "    text=remove_non_ar(text)\n",
    "    text=removing_ar_stopwords(text)\n",
    "    return remove_duplicate_letters(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a84589",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = pickle.load(open('xgbmodel.pkl', 'rb'))\n",
    "lstm_model = load_model('lstm_model.h5')\n",
    "tok = pickle.load(open('tokenizer.pkl', 'rb'))\n",
    "bert_model = pipeline(\"text-classification\", model=\"output_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={'AE': 16,'BH': 17,'DZ': 10,'EG': 11,'IQ': 0,'JO': 6,'KW': 13,'LB': 12,'LY': 1,'MA': 7,'OM': 14,'PL': 3,\n",
    "         'QA': 2,'SA': 8,'SD': 15,'SY': 4,'TN': 5,'YE': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "@app.route('/prediction', methods=['GET','POST'])\n",
    "def predict():\n",
    "    text=request.form['text']\n",
    "    text=preprocesss(text)\n",
    "    xgb_pred = xgb_model.predict([text])\n",
    "    encoded = tok.texts_to_sequences([text])\n",
    "    padded = pad_sequences(encoded,maxlen=280, padding='post')\n",
    "    lstm_pred = np.argmax(lstm_model.predict(padded))\n",
    "    lstm_pred = [k for k, v in mapping.items() if v == lstm_pred]\n",
    "    bert_pred = bert_model(text)\n",
    "    return render_template('prediction.html', prediction_string = 'Predictions :',\n",
    "                           svm = 'XGB prediction : {}'.format(svm_pred[0]),\n",
    "                           lstm = 'LSTM prediction : {}'.format(lstm_pred[0]),\n",
    "                           arabert = 'Arabert prediction : {}'.format(bert_pred[0]['label']))\n",
    "    \n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a776e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
